#!/usr/bin/env python
"""
Generates quality control reports on defined MRI data types. If no subject is
given, all subjects are submitted individually to the queue.

usage:
    dm-qc-report.py [options] <config>

Arguments:
    <config>           Project configuration file

Options:
    --subject SCANID   Scan ID to QC for. E.g. DTI_CMH_H001_01_01
    --rewrite          Rewrite the html of an existing qc page
    --debug            Be extra chatty

Details:
    This program QCs the data contained in <NiftiDir> and <DicomDir>, and
    outputs a myriad of metrics as well as a report in <QCDir>. All work is done
    on a per-subject basis.

    **data directories**

    The folder structure expected is that generated by xnat-export.py:

        <NiftiDir>/
           subject1/
               file1.nii.gz
               file2.nii.gz
           subject2/
               file1.nii.gz
               file2.nii.gz

        <DicomDir>/
           subject1/
               file1.dcm
               file2.dcm
           subject2/
               file1.dcm
               file2.dcm

     There should be a .dcm file for each .nii.gz. One subfolder for each
     subject will be created under the <QCDir> folder.

     **gold standards**

     To check for changes to the MRI machine's settings over time, this compares
     the headers found in <DicomDir> with the appropriate dicom file found in
     <StandardsDir>/<Tag>/filename.dcm.

     **configuration file**

     The locations of the dicom folder, nifti folder, qc folder, gold standards
     folder, log folder, and expected set of scans are read from the supplied
     configuration file with the following structure:

     paths:
       dcm: '/archive/data/SPINS/data/dcm'
       nii: '/archive/data/SPINS/data/nii'
       qc:  '/archive/data/SPINS/qc'
       std: '/archive/data/SPINS/metadata/standards'
       log: '/archive/data/SPINS/log'

     Sites:
       site1:
         XNAT_Archive: '/path/to/arc001'
         ExportInfo:
           - T1:  {Pattern: {'regex1', 'regex2'}, Count: n_expected}
           - DTI: {Pattern: {'regex1', 'regex2'}, Count: n_expected}
       site2 :
         XNAT_Archive: '/path/to/arc001'
         ExportInfo:
           - T1:  {Pattern: {'regex1', 'regex2'}, Count: n_expected}
           - DTI: {Pattern: {'regex1', 'regex2'}, Count: n_expected}
Requires:
    FSL
    QCMON
"""

import os, sys
import re
import glob
import time
import logging

import numpy as np
import pandas as pd

import datman as dm
from datman.docopt import docopt

logging.basicConfig(level=logging.WARN, format="[%(name)s] %(levelname)s: %(message)s")
logger = logging.getLogger(os.path.basename(__file__))

REWRITE = False

def slicer(fpath, pic, slicergap, picwidth):
    """
    Uses FSL's slicer function to generate a montage png from a nifti file
        fpath       -- submitted image file name
        slicergap   -- int of "gap" between slices in Montage
        picwidth    -- width (in pixels) of output image
        pic         -- fullpath to for output image
    """
    dm.utils.run("slicer {} -S {} {} {}".format(fpath,slicergap,picwidth,pic))

def add_image(qc_html, image, title=None):
    """
    Adds an image to the report.
    """
    if title:
        qc_html.write('<center> {} </center>'.format(title))

    relpath = os.path.relpath(image, os.path.dirname(qc_html.name))
    qc_html.write('<a href="'+ relpath + '" >')
    qc_html.write('<img src="' + relpath + '" >')
    qc_html.write('</a><br>\n')

    return qc_html
# PIPELINES
def ignore(filename, qc_dir, report):
    pass

def phantom_fmri_qc(filename, outputDir):
    """
    Runs the fbirn fMRI pipeline on input phantom data if the outputs don't
    already exist.
    """
    basename = nifti_basename(filename)
    output_file = os.path.join(outputDir, '{}_stats.csv'.format(basename))
    output_prefix = os.path.join(outputDir, basename)
    if not os.path.isfile(output_file):
        dm.utils.run('qc-fbirn-fmri {} {}'.format(filename, output_prefix))

def phantom_dti_qc(filename, outputDir):
    """
    Runs the fbirn DTI pipeline on input phantom data if the outputs don't
    already exist.
    """
    dirname = os.path.dirname(filename)
    basename = dm.utils.nifti_basename(filename)

    output_file = os.path.join(outputDir, '{}_stats.csv'.format(basename))
    output_prefix = os.path.join(outputDir, basename)

    if not os.path.isfile(output_file):
        bvec = os.path.join(dirname, basename + '.bvec')
        bval = os.path.join(dirname, basename + '.bval')
        dm.utils.run('qc-fbirn-dti {} {} {} {} n'.format(filename, bvec, bval, output_prefix))

def phantom_anat_qc(filename, outputDir):
    """
    Runs the ADNI pipeline on input phantom data if the outputs don't already
    exist.
    """
    basename = dm.utils.nifti_basename(filename)
    output_file = os.path.join(outputDir, '{}_adni-contrasts.csv'.format(basename))
    if not os.path.isfile(output_file):
        dm.utils.run('qc-adni {} {}'.format(filename, output_file))

def fmri_qc(file_name, qc_dir, report):
    base_name = dm.utils.nifti_basename(file_name)
    output_name = os.path.join(qc_dir, base_name)

    # check scan length
    script_output = output_name + '_scanlengths.csv'
    if not os.path.isfile(script_output):
        dm.utils.run('qc-scanlength {} {}'.format(file_name, script_output))

    # check fmri signal
    script_output = output_name + '_stats.csv'
    if not os.path.isfile(script_output):
        dm.utils.run('qc-fmri {} {}'.format(file_name, output_name))

    image_raw = output_name + '_raw.png'
    image_sfnr = output_name + '_sfnr.png'
    image_corr = output_name + '_corr.png'

    if not os.path.isfile(image_raw):
        slicer(file_name, image_raw, 2, 1600)
    add_image(report, image_raw, title='BOLD montage')

    if not os.path.isfile(image_sfnr):
        slicer(os.path.join(qc_dir, base_name + '_sfnr.nii.gz'), image_sfnr, 2, 1600)
    add_image(report, image_sfnr, title='SFNR map')

    if not os.path.isfile(image_corr):
        slicer(os.path.join(qc_dir, base_name + '_corr.nii.gz'), image_corr, 2, 1600)
    add_image(report, image_corr, title='correlation map')

def anat_qc(filename, qc_dir, report):

    image = os.path.join(qc_dir, dm.utils.nifti_basename(filename) + '.png')
    if not os.path.isfile(image):
        slicer(filename, image, 5, 1600)
    add_image(report, image)

def dti_qc(filename, qc_dir, report):
    dirname = os.path.dirname(filename)
    basename = dm.utils.nifti_basename(filename)

    bvec = os.path.join(dirname, basename + '.bvec')
    bval = os.path.join(dirname, basename + '.bval')

    output_prefix = os.path.join(qc_dir, basename)
    output_file = output_prefix + '_stats.csv'
    if not os.path.isfile(output_file):
        dm.utils.run('qc-dti {} {} {} {}'.format(filename, bvec, bval, output_prefix))

    output_file = os.path.join(qc_dir, basename + '_spikecount.csv')
    if not os.path.isfile(output_file):
        dm.utils.run('qc-spikecount {} {} {}'.format(filename, os.path.join(qc_dir, basename + '_spikecount.csv'), bval))

    image = os.path.join(qc_dir, basename + '_b0.png')
    if not os.path.isfile(image):
        slicer(filename, image, 2, 1600)
    add_image(report, image, title='b0 montage')
    add_image(report, os.path.join(qc_dir, basename + '_directions.png'), title='bvec directions')

def submit_qc_jobs(commands):
    """
    Submits the given commands to the queue.
    """
    for i, cmd in enumerate(commands):
        jobname = "qc_report_{}_{}".format(time.strftime("%Y%m%d-%H%M%S"), i)
        logfile = '/tmp/{}.log'.format(jobname)
        errfile = '/tmp/{}.err'.format(jobname)

        run_cmd = 'echo {} | qsub -V -q main.q ' \
                '-o {} -e {} -N {}'.format(cmd, logfile, errfile, jobname)

        rtn, out = dm.utils.run(run_cmd)

        if rtn:
            logger.error("stdout: {}".format(out))
        else:
            logger.debug(out)

def make_qc_command(subject_id, config_file):
    command = " ".join([__file__, config_file, '--subject {}'.format(subject_id)])
    if REWRITE:
        command.append(' --rewrite')
    return command

def qc_all_scans(subject, config):
    """
    Creates a dm-qc-report.py command for each scan and submits any
    commands for human subjects to the queue to run.
    """
    human_commands = []
    phantom_commands = []

    nii_dir = config.get_path('nii')

    for path in os.listdir(nii_dir):
        command = make_qc_command(subject.full_id, config.path)
        if '_PHA_' in subject_id:
            phantom_commands.append(command)
        else:
            human_commands.append(command)

    if human_commands:
        submit_qc_jobs(human_commands)

    if phantom_commands:
        for cmd in phantom_commands:
            rtn, out = dm.utils.run(cmd)
            if rtn:
                logger.error("stdout: {}".format(out))

def find_existing_reports(checklist_path):
    found_reports = []
    with open(checklist_path, 'r') as checklist:
        for checklist_entry in checklist:
            checklist_entry = checklist_entry.split(' ')[0].strip()
            checklist_entry, checklist_ext = os.path.splitext(checklist_entry)
            found_reports.append(checklist_entry)
    return found_reports

def add_report_to_checklist(qc_report, checklist_path):
    """
    Add the given report's name to the QC checklist if it is not already
    present.
    """
    if not qc_report:
        return

    # remove extension from report name, so we don't double-count .pdfs vs .html
    report_name, report_ext = os.path.splitext(qc_report)

    try:
        found_reports = find_existing_reports(checklist_path)
    except IOError:
        logger.info("{} does not exist. "\
                "Attempting to create it".format(checklist_path))
        found_reports = []

    if report_name in found_reports:
        return

    with open(checklist_path, 'a') as checklist:
        checklist.write(os.path.basename(report_name + report_ext) + '\n')

def add_header_qc(nifti_path, qc_html, log_path):
    """
    Adds header-diff.log information to the report.
    """
    # get the filename of the nifti in question
    filestem = os.path.basename(nifti_path).replace(
            dm.utils.get_extension(nifti_path),'')

    try:
        # read the log
        with open(log_path, 'r') as f:
            f = f.readlines()
    except IOError:
        logger.info("header-diff.log not found. Generating page without it.")
        f = []

    # find lines in said log that pertain to the nifti
    lines = [re.sub('^.*?: *','',line) for line in f if filestem in line]

    if not lines:
        return

    qc_html.write('<h3> {} header differences </h3>\n<table>'.format(filestem))
    for l in lines:
        qc_html.write('<tr><td>{}</td></tr>'.format(l))
    qc_html.write('</table>\n')

def find_tech_notes(path):
    """
    Search the file tree rooted at path for the tech notes pdf
    """
    resource_folders = glob.glob(path + "*")

    if resource_folders:
        resources = resource_folders[0]
    else:
        resources = ""

    for root, dirs, files in os.walk(resources):
        for fname in files:
            if ".pdf" in fname:
                return os.path.join(root, fname)
    return ""

def write_tech_notes_link(report, subject_id, resources_path):
    """
    Adds a link to the tech notes for this subject to the given QC report
    """
    tech_notes = ""
    if 'CMH' in subject_id:
        tech_notes = find_tech_notes(resources_path)

    if not tech_notes:
        report.write('<p>Tech Notes not found</p>\n')
        return

    notes_path = os.path.relpath(os.path.abspath(tech_notes),
                        os.path.dirname(report.name))
    report.write('<a href="{}">'.format(notes_path))
    report.write('Click Here to open Tech Notes')
    report.write('</a><br>')

def write_table(report, exportinfo):
    report.write('<table><tr>'
                 '<th>Tag</th>'
                 '<th>File</th>'
                 '<th>Notes</th></tr>')

    for row in range(0,len(exportinfo)):
        report.write('<tr><td>{}</td>'.format(exportinfo.loc[row,'tag'])) ## table new row
        report.write('<td><a href="#{}">{}</a></td>'.format(exportinfo.loc[row,'bookmark'],exportinfo.loc[row,'File']))
        report.write('<td><font color="#FF0000">{}</font></td></tr>'.format(exportinfo.loc[row,'Note'])) ## table new row
    report.write('</table>\n')

def write_report_header(report, subject_id):
    report.write('<HTML><TITLE>{} qc</TITLE>\n'.format(subject_id))
    report.write('<head>\n<style>\n'
                'body { font-family: futura,sans-serif;'
                '        text-align: center;}\n'
                'img {width:90%; \n'
                '   display: block\n;'
                '   margin-left: auto;\n'
                '   margin-right: auto }\n'
                'table { margin: 25px auto; \n'
                '        border-collapse: collapse;\n'
                '        text-align: left;\n'
                '        width: 90%; \n'
                '        border: 1px solid grey;\n'
                '        border-bottom: 2px solid black;} \n'
                'th {background: black;\n'
                '    color: white;\n'
                '    text-transform: uppercase;\n'
                '    padding: 10px;}\n'
                'td {border-top: thin solid;\n'
                '    border-bottom: thin solid;\n'
                '    padding: 10px;}\n'
                '</style></head>\n')

    report.write('<h1> QC report for {} <h1/>'.format(subject_id))

def initialize_counts(export_info):
    # build a tag count dict
    tag_counts = {}
    expected_position = {}

    for tag in export_info.tags:
        tag_counts[tag] = 0
        tag_info = export_info.get_tag_info(tag)

        # If ordering has been imposed on the scans get it for later sorting.
        if 'Order' in tag_info.keys():
            expected_position[tag] = min([tag_info['Order']])
        else:
            expected_position[tag] = 0

    return tag_counts, expected_position

def get_sorted_niftis(scan_path):
    niftis = []
    for item in glob.glob(os.path.join(scan_path, '*')):
        if dm.utils.get_extension(item) in ['.nii.gz', '.nii']:
            niftis.append(os.path.basename(item))

    # Sort niftis by their series number
    niftis = sorted(niftis, key=lambda x: dm.scanid.parse_filename(x)[2])

    return niftis

def find_expected_files(subject, config):
    """
    Reads the export_info from the config for this site and compares it to the
    contents of the nii folder. Data written to a pandas dataframe.
    """
    export_info = config.get_export_info(subject.site)
    niftis = get_sorted_niftis(subject.nii)

    tag_counts, expected_positions = initialize_counts(export_info)

    # init output pandas data frame, counter
    idx = 0
    expected_files = pd.DataFrame(columns=['tag', 'File', 'bookmark', 'Note',
            'Sequence'])

    # tabulate found data in the order they were acquired
    for file_name in niftis:
        tag = dm.scanid.parse_filename(file_name)[1]

        # only check data that is defined in the config file
        if tag in export_info.tags:
            expected_count = export_info.get_tag_info(tag)['Count']
        else:
            continue

        tag_counts[tag] += 1
        bookmark = tag + str(tag_counts[tag])
        if tag_counts[tag] > expected_count:
            notes = 'Repeated Scan'
        else:
            notes = ''

        position = get_position(expected_positions[tag])

#####################################################################
        # TODO If the list is empty pop will crash. Fix
        if isinstance(expected_positions[tag], list):
            position = expected_positions[tag].pop(0)
        else:
            position = expected_positions[tag]

        expected_files.loc[idx] = [tag, file_name, bookmark, notes,
                position]
        idx += 1
######################################################################

    # note any missing data
    for tag in export_info.tags:
        expected_count = export_info.get_tag_info(tag)['Count']
        if tag_counts[tag] < expected_count:
            n_missing = expected_count - tag_counts[tag]
            notes = 'missing({})'.format(expected_count - tag_counts[tag])
            expected_files.loc[idx] = [tag, '', '', notes,
                    expected_positions[tag]]
            idx += 1
    expected_files = expected_files.sort('Sequence')
    return(expected_files)

def run_header_qc(dicom_dir, standard_dir, log_file):
    """
    For each .dcm file found in 'dicoms', find the matching site/tag file in
    'standards', and run qc-headers (from qcmon) on these files. Any
    are written to log_file.
    """

    dicoms = glob.glob(os.path.join(dicom_dir, '*'))
    standards = glob.glob(os.path.join(standard_dir, '*'))

    if not dicoms:
        logger.debug("No dicoms found in {}".format(dicom_dir))
        return

    site = dm.scanid.parse_filename(dicoms[0])[0].site

    # build standard dict
    standardDict = {}
    for s in standards:
        if dm.scanid.parse_filename(s)[0].site == site:
            standardDict[dm.scanid.parse_filename(s)[1]] = s

    for d in dicoms:
        tag = dm.scanid.parse_filename(d)[1]
        try:
            s = standardDict[tag]
        except:
            logger.debug('No standard with tag {} found in {}'.format(tag,
                    standard_dir))
            continue

        # run header check for dicom
        dm.utils.run('qc-headers {} {} {}'.format(d, s, log_file))

    if not os.path.exists(log_file):
        subject = os.path.basename(dicom_dir)
        logger.error("header-diff.log not generated for {}. ".format(subject) +
                " Check that gold standards are present for this site.")

def qc_subject(subject, config):
    """
    subject :           The created Scan object for the subject_id this run
    config :            The settings obtained from project_settings.yml

    Returns the path to the qc_<subject_id>.html file
    """
    handlers = {   # map from tag to QC function
        "T1"            : anat_qc,
        "T2"            : anat_qc,
        "PD"            : anat_qc,
        "PDT2"          : anat_qc,
        "FLAIR"         : anat_qc,
        "FMAP"          : ignore,
        "FMAP-6.5"      : ignore,
        "FMAP-8.5"      : ignore,
        "RST"           : fmri_qc,
        "EPI"           : fmri_qc,
        "SPRL"          : fmri_qc,
        "OBS"           : fmri_qc,
        "IMI"           : fmri_qc,
        "NBK"           : fmri_qc,
        "EMP"           : fmri_qc,
        "VN-SPRL"       : fmri_qc,
        "SID"           : fmri_qc,
        "MID"           : fmri_qc,
        "DTI"           : dti_qc,
        "DTI21"         : dti_qc,
        "DTI22"         : dti_qc,
        "DTI23"         : dti_qc,
        "DTI60-29-1000" : dti_qc,
        "DTI60-20-1000" : dti_qc,
        "DTI60-1000"    : dti_qc,
        "DTI60-b1000"   : dti_qc,
        "DTI33-1000"    : dti_qc,
        "DTI33-b1000"   : dti_qc,
        "DTI33-3000"    : dti_qc,
        "DTI33-b3000"   : dti_qc,
        "DTI33-4500"    : dti_qc,
        "DTI33-b4500"   : dti_qc,
        "DTI23-1000"    : dti_qc,
        "DTI69-1000"    : dti_qc,
    }

    report_name = os.path.join(subject.qc, 'qc_{}.html'.format(subject.full_id))
    resources_path = subject.resources

    if os.path.isfile(report_name):
        if not REWRITE:
            logger.debug("{} exists, skipping.".format(report_name))
            return
        os.remove(report_name)

    # header diff
    header_diffs = os.path.join(subject.qc, 'header-diff.log')
    if not os.path.isfile(header_diffs):
        run_header_qc(subject.dcm, config.get_path('std'), header_diffs)

    expected_files = find_expected_files(subject, config)

    with open(report_name, 'wb') as report:
        write_report_header(report, subject.full_id)
        write_table(report, expected_files)
        write_tech_notes_link(report, subject.full_id, subject.resources)
        # write_report_body
        for idx in range(0,len(expected_files)):
            name = expected_files.loc[idx,'File']
            if name:
                fname = os.path.join(subject.nii, name)
                logger.info("QC scan {}".format(fname))
                ident, tag, series, description = dm.scanid.parse_filename(fname)
                report.write('<h2 id="{}">{}</h2>\n'.format(expected_files.loc[idx,'bookmark'], name))

                if tag not in handlers:
                    logger.info("No QC tag {} for scan {}. Skipping.".format(tag, fname))
                    continue

                add_header_qc(fname, report, header_diffs)

                handlers[tag](fname, subject.qc, report)
                report.write('<br>')


    return report_name

def qc_phantom(subject, config):
    """
    subject:            The Scan object for the subject_id of this run
    config :            The settings obtained from project_settings.yml
    """
    handlers = {
        "T1"            : phantom_anat_qc,
        "RST"           : phantom_fmri_qc,
        "DTI60-1000"    : phantom_dti_qc,
    }

    glob_path = os.path.join(subject.nii, '*.nii.gz')
    niftis = glob.glob(glob_path)

    for nifti in niftis:
        ident, tag, series, description = dm.scanid.parse_filename(nifti)
        if tag not in handlers:
            logger.info("No QC tag {} for scan {}. Skipping.".format(tag, nifti))
            continue
        handlers[tag](nifti, subject.qc)

def qc_single_scan(subject, config):
    """
    Perform QC for a single subject or phantom. Return the report name if one
    was created.
    """

    if 'PHA' in subject.full_id:
        logger.info("QC phantom {}".format(subject.nii))
        qc_phantom(subject, config)
        return ""

    logger.info("QC {}".format(subject.nii))
    report_name = qc_subject(subject, config)
    return report_name

def prepare_scan(subject_id, config):
    """
    Makes a new 'Scan' object, checks for errors (namely a bad subject_id),
    removes empty files present in existing nifti/qc directories for this scan
    and ensures the qc folder exists for this scan.
    """
    try:
        subject = Scan(subject_id, config)
    except dm.scanid.ParseException:
        logging.error("{} does not match the datman naming convention. " \
                "Exiting".format(subject_id))
        sys.exit(1)

    dm.utils.remove_empty_files(subject.get_path('nii'))

    qc_dir = dm.utils.define_folder(subject.get_path('qc'))
    # If qc_dir already existed and had empty files left over clean up
    dm.utils.remove_empty_files(qc_dir)

    return subject

def get_site_config(config_path):
    """
    Ensures the path to the given yaml file is readable and contains
    the expected paths. Returns an instance of SiteConfig (from
    datman.siteconfig.py).

    Raises sys.exit if the config file is unreadable or missing paths.
    """
    try:
        config = SiteConfig(config_path)
    except IOError:
        logging.error("{} cannot be read.".format(config_path))
        sys.exit(1)

    expected_paths = set(['dcm', 'nii', 'qc', 'std', 'meta'])
    undefined_paths = expected_paths - set(config.paths)

    if undefined_paths:
        logging.error("paths: {} not defined in {}".format(undefined_paths,
                config_path))
        sys.exit(1)

    return config

def main():

    global REWRITE

    arguments = docopt(__doc__)

    config_path = arguments['<config>']
    scanid      = arguments['--subject']
    REWRITE     = arguments['--rewrite']
    debug       = arguments['--debug']

    if debug:
        logging.getLogger().setLevel(logging.DEBUG)

    config = get_site_config(config_path)

    if scanid:
        subject = prepare_scan(scanid, config)

        qc_report = qc_single_scan(subject, config)

        checklist_path = os.path.join(config.get_path('meta'), 'checklist.csv')
        add_report_to_checklist(qc_report, checklist_path)
        return

    qc_all_scans(subject, config)

if __name__ == "__main__":
    main()
