#!/usr/bin/env python
"""
This builds a Github Pages site using the phantom (and possibly other) QC
plots generated by datman, commits those changes, and finally pushes them
up to github. This way, the online dashboards can be updated automatically.

Usage:
    web-build.py [options] <project>

Arguments: 
    <project>           Full path to the project directory containing data/.

Options:
    -v,--verbose             Verbose logging
    --debug                  Debug logging

DETAILS

    This finds outputs of qc-phantom.py (and potentially eventually qc.py),
    and syncs them to the website project for rendering on the web.

    This assumes you've set up the website/ folder using the template. 

    This message is printed with the -h, --help flags.
"""

import sys, os
from copy import copy
from docopt import docopt
import datman as dm

VERBOSE = False
DRYRUN  = False
DEBUG   = False

# # template text used to generate each post note Y2K+100 BUG!
# HEADER = """\
# ---
# category: {imagetype}
# title: {imagetype} 20{date}
# tags: [{imagetype}]
# ---
# """

# BODY = """\
# <figure>
#     <a href="{{{{ production_url }}}}/{proj}/assets/images/{imagetype}/{fname}">\
# <img src="{{{{ production_url }}}}/{proj}/assets/images/{imagetype}/{fname}"></a>
# </figure>

# """

# def filter_posted(files, dates):
#     """
#     This removes files containing any of the dates supplied in the filename.
#     """
#     for date in dates:
#         files = filter(lambda x: date not in x, files)

#     return files

# def get_unique_dates(files, begin=2, end=10):
#     """
#     Gets all the unique dates in a list of input files. Defined as a region 
#     of the input file that begins at 'begin' and ends and 'end.'
#     """
#     dates = copy(files)
#     for i, f in enumerate(files):
#         dates[i] = f[begin:end]
#     dates = list(set(dates))

#     return dates

# def get_posted_dates(base_path):
#     """
#     This gets all of the currently posted dates from the website.
#     """
#     try:
#         posts = os.listdir('{}/website/_posts/'.format(base_path))
#         posts = get_unique_dates(posts, 2, 10)

#     except:
#         print("""Bro, you don't even have a website."""
#               """Clone one into website/ from"""
#               """https://github.com/TIGRLab/data-website""")
#         sys.exit()

#     return posts

def get_latest_files(base_path):
    """
    This gets the output .csvs for the adni, fmri, and dti qc plots, and 
    returns the paths to each. If a type of these outputs does not exist 
    for a given study, we return None for that type.
    """
    try:
        adni = os.listdir('{}/qc/phantom/adni'.format(base_path))
        adni = filter(lambda x: '_adni_' in x and 'csv' in x, adni)
        adni.sort()
        adni = adni[-9:]
    except:
        adni = None

    try:
        fmri = os.listdir('{}/qc/phantom/fmri'.format(base_path))
        fmri = filter(lambda x: '_fmri_' in x and 'csv' in x, fmri)
        fmri.sort()
        fmri = fmri[-7:]
    except:
        fmri = None

    try:
        dti = os.listdir('{}/qc/phantom/dti'.format(base_path))
        dti = filter(lambda x: '_dti_' in x and 'csv' in x, dti)
        dti.sort()
        dti = dti[-1:]
    except:
        dti = None

    return adni, fmri, dti

def get_imagetype_from_filename(filename):
    """
    Determines the type of plot from the filename.
    """
    if 'adni' in filename.lower():
        imagetype = 'adni'
    elif 'fmri' in filename.lower():
        imagetype = 'fmri'
    elif 'dti' in filename.lower():
        imagetype = 'dti'
    else:
        print('ERROR: Unknown input file ' + f)
        imagetype = None

    return imagetype

def convert_to_web(base_path, files):
    """
    Converts .pdfs to .pngs in the website folder. Also changes the associated
    filenames to contain the new file extensions.
    """
    for i, f in enumerate(files):
        imagetype = get_imagetype_from_filename(f)
        cmd = ('rsync '
               '{base_path}/qc/phantom/{imagetype}/{f} '
               '{base_path}/website/assets/{output}'.format(
                    base_path=base_path, imagetype=imagetype, 
                    f=f, output=f[9:]))
        os.system(cmd)

# def create_posts(base_path, files):
#     """
#     Loops through unique dates, and generates a jekyll post for each one using
#     all of the images from that date.
#     """

#     proj = dm.utils.mangle_basename(base_path)
#     imagetype = get_imagetype_from_filename(files[0])
#     dates = get_unique_dates(files, 0, 8)

#     for date in dates:
        
#         current_files = filter(lambda x: date in x, files)

#         # NB: Y2K+100 BUG
#         post_name = '{base_path}/website/_posts/{date}-{imagetype}.md'.format(
#                         base_path=base_path, 
#                         date='20' + date, 
#                         imagetype=imagetype)
        
#         # write header, loop through files, write body for each
#         f = open(post_name, 'wb')
#         f.write(HEADER.format(imagetype=imagetype, date=date))
#         for fname in current_files:
#              f.write(BODY.format(proj=proj, imagetype=imagetype, fname=fname))
#         f.close()

#         print('Wrote page for ' + imagetype + ' ' + date + '.')

def main():

    arguments = docopt(__doc__)
    project   = arguments['<project>']
    VERBOSE   = arguments['--verbose']
    DEBUG     = arguments['--debug']

    # finds all of the dates we've already posted
    # dates = get_posted_dates(project)

    # gets a list of all the unposted pdfs
    adni, fmri, dti = get_latest_files(project)

    # syncs latest csv files to website
    if adni:
        print('converting ADNI')
        convert_to_web(project, adni)
        
    if fmri:
        print('converting fMRI')
        convert_to_web(project, fmri)
        
    if dti:
        print('converting DTI')
        convert_to_web(project, dti)

if __name__ == '__main__':
    main()
